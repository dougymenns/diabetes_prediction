{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f1f6f1cb769d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'diabetic_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = cleaning.drop_duplicates(\"patient_nbr\")\n",
    "cleaning = cleaning.drop(['encounter_id','patient_nbr','examide','citoglipton','weight','payer_code','glimepiride-pioglitazone'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute race,diag123 with mode\n",
    "cleaning.race.fillna(cleaning.race.mode().iloc[0], inplace=True)\n",
    "cleaning.diag_1.fillna(cleaning.diag_1.mode().iloc[0], inplace=True)\n",
    "cleaning.diag_2.fillna(cleaning.diag_2.mode().iloc[0], inplace=True)\n",
    "cleaning.diag_3.fillna(cleaning.diag_3.mode().iloc[0], inplace=True)\n",
    "cleaning.medical_specialty.fillna(cleaning.medical_specialty.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_top_14 = ['InternalMedicine','Emergency/Trauma','Family/GeneralPractice','Cardiology',\\\n",
    "              'Surgery-General','Nephrology','Orthopedics','Orthopedics-Reconstructive','Radiologist','Pulmonology',\\\n",
    "              'Psychiatry','Urology','ObstetricsandGynecology','Surgery-Cardiovascular/Thoracic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning['med_spec'] = cleaning['medical_specialty'].copy()\n",
    "\n",
    "# replace all specialties not in top 14 with 'Other' category\n",
    "cleaning.loc[~cleaning.med_spec.isin(med_top_14),'med_spec'] = 'Other_Disease'\n",
    "cleaning.drop(['medical_specialty'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_gender = LabelEncoder()\n",
    "cleaning.gender = le_gender.fit_transform(cleaning.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = cleaning\n",
    "final = pd.get_dummies(check['race'], drop_first=True)\n",
    "cleaning.drop(['race'],axis=1,inplace=True)\n",
    "cleaning = pd.concat([final,cleaning], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning.age = le_gender.fit_transform(cleaning.age)\n",
    "cleaning.max_glu_serum = le_gender.fit_transform(cleaning.max_glu_serum)\n",
    "cleaning['diabetesMed'] = le_gender.fit_transform(cleaning['diabetesMed'])\n",
    "cleaning['change'] = le_gender.fit_transform(cleaning['change'])\n",
    "cleaning['metformin-pioglitazone'] = le_gender.fit_transform(cleaning['metformin-pioglitazone'])\n",
    "cleaning['metformin-rosiglitazone'] = le_gender.fit_transform(cleaning['metformin-rosiglitazone'])\n",
    "cleaning['glipizide-metformin'] = le_gender.fit_transform(cleaning['glipizide-metformin'])\n",
    "cleaning['tolazamide'] = le_gender.fit_transform(cleaning['tolazamide'])\n",
    "cleaning['tolbutamide'] = le_gender.fit_transform(cleaning['tolbutamide'])\n",
    "cleaning['acetohexamide'] = le_gender.fit_transform(cleaning['tolbutamide'])\n",
    "cleaning['insulin'] = le_gender.fit_transform(cleaning['insulin'])\n",
    "cleaning['max_glu_serum'] = le_gender.fit_transform(cleaning['max_glu_serum'])\n",
    "cleaning['glyburide-metformin'] = le_gender.fit_transform(cleaning['glyburide-metformin'])\n",
    "cleaning['miglitol'] = le_gender.fit_transform(cleaning['miglitol'])\n",
    "cleaning['rosiglitazone'] = le_gender.fit_transform(cleaning['rosiglitazone'])\n",
    "cleaning['glyburide'] = le_gender.fit_transform(cleaning['glyburide'])\n",
    "cleaning['glipizide'] = le_gender.fit_transform(cleaning['glipizide'])\n",
    "cleaning['glimepiride'] = le_gender.fit_transform(cleaning['glimepiride'])\n",
    "cleaning['chlorpropamide'] = le_gender.fit_transform(cleaning['chlorpropamide'])\n",
    "cleaning['nateglinide'] = le_gender.fit_transform(cleaning['nateglinide'])\n",
    "cleaning['repaglinide'] = le_gender.fit_transform(cleaning['repaglinide'])\n",
    "cleaning['metformin'] = le_gender.fit_transform(cleaning['metformin'])\n",
    "cleaning['acarbose'] = le_gender.fit_transform(cleaning['acarbose'])\n",
    "cleaning['A1Cresult'] = le_gender.fit_transform(cleaning['A1Cresult'])\n",
    "cleaning['pioglitazone'] = le_gender.fit_transform(cleaning['pioglitazone'])\n",
    "cleaning['troglitazone'] = le_gender.fit_transform(cleaning['troglitazone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert diag_1 with e or v values to other\n",
    "cleaning.loc[cleaning['diag_1'].str.contains('E',na=False), 'diag_1'] = 0\n",
    "cleaning.loc[cleaning['diag_1'].str.contains('V',na=False), 'diag_1'] = 0\n",
    "cleaning.loc[cleaning['diag_2'].str.contains('E',na=False), 'diag_2'] = 0\n",
    "cleaning.loc[cleaning['diag_2'].str.contains('V',na=False), 'diag_2'] = 0\n",
    "cleaning.loc[cleaning['diag_3'].str.contains('E',na=False), 'diag_3'] = 0\n",
    "cleaning.loc[cleaning['diag_3'].str.contains('V',na=False), 'diag_3'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning.diag_1.dtypes\n",
    "cleaning.diag_1.astype('float')\n",
    "cleaning.diag_1 = cleaning.diag_1.str.split('.').str[0]\n",
    "cleaning.diag_1 = cleaning.diag_1.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning['diag_1'].value_counts()\n",
    "for index, col in cleaning.iterrows():\n",
    "    if (col['diag_1'] >= 390 and col['diag_1'] < 459  or col['diag_1'] == 785):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Circulatory'\n",
    "    elif (col['diag_1'] >= 460 and col['diag_1'] < 519  or col['diag_1'] == 786):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Respiratory'\n",
    "    elif (col['diag_1'] >= 520 and col['diag_1'] < 579  or col['diag_1'] == 787):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Respiratory'\n",
    "    elif (col['diag_1'] == 250):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Diabetes'\n",
    "    elif (col['diag_1'] >= 800 and col['diag_1'] < 999):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Injury'\n",
    "    elif (col['diag_1'] >= 710 and col['diag_1'] < 739):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Musculoskeletal'\n",
    "    elif (col['diag_1'] >= 580 and col['diag_1'] < 629  or col['diag_1'] == 788):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Genitourinary'\n",
    "    elif (col['diag_1'] >= 140 and col['diag_1'] < 239):\n",
    "        cleaning.loc[index, 'diag_1'] = 'Neoplasms'\n",
    "    else:\n",
    "        cleaning.loc[index, 'diag_1'] = 'Other_disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop secondary and other diag and focus on primary diag thus diag_1 for now\n",
    "cleaning.drop(['diag_2','diag_3'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_diag2_3 = pd.get_dummies(cleaning['diag_1'], drop_first=True)\n",
    "med_spec = pd.get_dummies(cleaning['med_spec'], drop_first=True)\n",
    "# remove diag_1 after ohe\n",
    "cleaning.drop(['diag_1'],axis=1,inplace=True)\n",
    "cleaning.drop(['med_spec'],axis=1,inplace=True)\n",
    "# concat ohe diag_1 to the main dataset\n",
    "cleaning = pd.concat([cleaning,remove_diag2_3,med_spec], axis=1)\n",
    "cleaning.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaning\n",
    "data[\"readmitted\"] = np.where(data[\"readmitted\"] == \">30\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.groupby('readmitted').apply(lambda x: x.sample(22240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(\"readmitted\", axis = 1)\n",
    "labels = data[\"readmitted\"]\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = data1.drop(\"readmitted\", axis = 1)\n",
    "labels1 = data1[\"readmitted\"]\n",
    "\n",
    "train_features1, test_features1, train_labels1, test_labels1 = train_test_split(features1, labels1, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = BalancedRandomForestClassifier()\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [20, 40, 60, 80, 100],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='recall', cv= 5)\n",
    "grid_rfc.fit(train_features, train_labels)\n",
    "print(grid_rfc.best_params_)\n",
    "print(grid_rfc.best_score_)\n",
    "#print(cross_val_score(rfc, features, labels, cv=5))\n",
    "#rfc.fit(train_features, train_labels)\n",
    "#rfc.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200)\n",
    "#print(cross_val_score(clf, features, labels, cv=5))\n",
    "clf.fit(train_features, train_labels)\n",
    "#clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "print(cross_val_score(neigh, features, labels, cv=5, scoring=\"recall\"))\n",
    "#neigh.fit(train_features, train_labels)\n",
    "#neigh.score(test_features, test_labels)\n",
    "neigh.fit(train_features1, train_labels1)\n",
    "print(neigh.score(test_features1, test_labels1))\n",
    "predn = neigh.predict(test_features1)\n",
    "print(classification_report(test_labels1, predn, target_names=[\"no\", \"read\"]))\n",
    "print(confusion_matrix(test_labels1, predn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc = RandomForestClassifier(class_weight = \"balanced\", oob_score=\"True\", n_estimators=200, max_features= 'sqrt', max_depth =20)\n",
    "rfc = BalancedRandomForestClassifier(oob_score=\"True\", n_estimators=300, max_features= 'auto', max_depth =20, criterion='entropy', random_state=42)\n",
    "rfc.fit(train_features, train_labels)\n",
    "print(rfc.score(test_features, test_labels))\n",
    "pred = rfc.predict(test_features)\n",
    "print(classification_report(test_labels, pred, target_names=[\"no\", \"read\"]))\n",
    "print(confusion_matrix(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight = \"balanced\", oob_score=\"True\", n_estimators=200, max_features= 'sqrt', max_depth =80, random_state=42)\n",
    "rfc.fit(train_features, train_labels)\n",
    "print(rfc.score(test_features, test_labels))\n",
    "pred = rfc.predict(test_features)\n",
    "print(classification_report(test_labels, pred, target_names=[\"no\", \"read\"]))\n",
    "print(confusion_matrix(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for num, x in enumerate(rfc.feature_importances_):\n",
    "    f.append([features.columns[num], x])\n",
    "    \n",
    "temp = sorted(f, key=lambda x: x[1])\n",
    "temp.reverse()\n",
    "for x in temp:\n",
    "    print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
